# 실리콘밸리에서 날아온 데이터 엔지니어링 스타터 키트 with Python


📈 커리큘럼

🗓 1주차 : 데이터 팀과 데이터 웨어하우스 소개
회사에서 데이터 조직이 하는 일이 무엇인지 여러 각도에서 살펴보고, 어떤 구성원들이 존재하는지 알아봅니다. 데이터 조직에서 데이터 엔지니어가 하는 역할과 필요한 스킬 셋에 대해 자세히 알아보고 실제 테크 기업 데이터 엔지니어의 하루를 살펴봅니다.

✅ 데이터 팀의 구성과 역할에 대한 이해
✅ 데이터 팀에서 데이터 엔지니어의 역할은
✅ 데이터 웨어하우스 소개
🧑🏻‍💻 [과제] Python을 활용한 Redshift access

주요 키워드 : 데이터 팀의 역할, 데이터 팀의 구성원(데이터 엔지니어, 데이터 애널리스트, 데이터 사이언티스트)과 역할, ETL (Extract, Transform, Load)/데이터 잡/데이터 파이프라인, 데이터 잡 스케줄러, Airflow, 데이터 웨어하우스 (Redshift, Snowflake, BigQuery)


🗓 2주차 : 데이터 엔지니어링을 위한 SQL
데이터 엔지니어에게 가장 중요한 스킬 셋은 바로 SQL! 통상적으로 개발자가 쓰는 SQL과 비교해 데이터 엔지니어링에서 쓰는 SQL은 무엇이 다른지 알아봅니다. 예제 데이터를 토대로 복잡한 SQL을 사용하는 방법을 학습해봅니다.

✅ SQL 소개
✅ 고급 SQL
🧑🏻‍💻 [과제] 조금 더 복잡도가 높은 실제 현업 데이터를 토대로 앞서 실습했던 metrics들을 계산해보기

주요 키워드 : 기초 SQL과 데이터 엔지니어링을 위한 고급 SQL, JOIN, LEFT JOIN, OUTER JOIN, SQL Aggregate functions, UNION, EXCEPT, SQL UDF, Cohort, Redshift


🗓 3주차 : ETL(Extract, Transform and Load) 작성하기
파이썬으로 간단한 ETL을 작성해 보고, Airflow가 어떻게 도움이 되는지 알아봅니다. 앞서 작성한 간단한 ETL을 Airflow로 변환해 봅니다.

✅ ETL 개념 및 ETL 작성
✅ Airflow 소개

주요 키워드 : ETL, 데이터 파이프라인, 데이터 잡, 스케줄러, Python, SQL, Airflow, Redshift, Airflow DAG/Task/Operator


🗓 4주차 : Airflow 심화학습 #1
좀 더 복잡한 데이터를 다뤄보며 Airflow의 여러 기능에 대해 배워봅니다. 써머리 테이블을 직접 만들어 보면서 raw data가 어떻게 이해하기 쉬운 형태로 추상화되는지 확인해봅니다.

✅ Airflow 코드에서 SQL 트랜잭션 사용해보기
✅ Airflow 기반 ETL 작성 : OpenWeather API 기반 DAG
✅ Redshift에서 Primary key uniqueness를 보장하기

주요 키워드 : Airflow 파라미터 설명, Airflow의 태스크/DAG 실행순서 정의, Airflow troubleshooting


🗓 5주차 : Airflow 심화학습 #2
Airflow를 사용하는 가장 중요한 이유 중의 하나인 Backfill에 대해 배워봅니다. 다음으로 Summary table을 만드는 DAG를 구현해 봅니다.

✅ Airflow Backfill 과정 이해하기
✅ Airflow 기반 ETL 작성 : Summary table 만들기

주요 키워드 : Backfill, Summary table


🗓 6주차 : Airflow Production 운영하기
Airflow를 실제로 운영한다는 가정하에 필요한 다양한 주제들을 다뤄보고 과정을 마무리합니다.

✅ Airflow를 프로덕션 환경에서 운영할 때 알아야할 점
✅ 기타 Airflow 관련 팁들

주요 키워드 : Backfill, Airflow production


🗓 7주차 : 커리어톡
✅ 데이터 엔지니어 커리어 로드맵
주요 키워드 : 데이터 엔지니어 커리어
